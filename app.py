#################################################################################
# FDS
# Original Service https://chat2vis.streamlit.app/
# Original work by @frog-land. Modified by @paulinayoun.
#################################################################################
from dotenv import load_dotenv
import os
import pandas as pd
import openai
from openai import OpenAI
import streamlit as st
#import streamlit_nested_layout
from classes import get_primer,format_question,run_request
import warnings
import time
load_dotenv()

API_KEY=os.environ['OPENAI_API_KEY']
client = OpenAI(api_key=API_KEY)

warnings.filterwarnings("ignore")
st.set_option('deprecation.showPyplotGlobalUse', False)
st.set_page_config(page_icon="ğŸ’°",layout="wide",page_title="FDS í…ŒìŠ¤íŠ¸ í˜ì´ì§€")

st.markdown("<h4 style='text-align: center;padding-top: 0rem;'>í…ŒìŠ¤íŠ¸</h4>", unsafe_allow_html=True)

available_models = {"ChatGPT-3.5": "gpt-3.5-turbo"}

# available_models = {"ChatGPT-3.5": "gpt-3.5-turbo", "GPT-3.5 Instruct": "gpt-3.5-turbo-instruct"}

# List to hold datasets
if "datasets" not in st.session_state:
    datasets = {}
    # Preload datasets
    datasets["ì´ê³„ì •ì›ì¥"] =pd.read_csv("files\glsample.csv")
    st.session_state["datasets"] = datasets
else:
    # use the list already loaded
    datasets = st.session_state["datasets"]


with st.sidebar:
    # First we want to choose the dataset, but we will fill it with choices once we've loaded one
    dataset_container = st.empty()

    # Add facility to upload a dataset
    try:
        uploaded_file = st.file_uploader(":computer: Load a CSV file:", type="csv")
        index_no=0
        if uploaded_file:
            # Read in the data, add it to the list of available datasets. Give it a nice name.
            file_name = uploaded_file.name[:-4].capitalize()
            datasets[file_name] = pd.read_csv(uploaded_file)
            # We want to default the radio button to the newly added dataset
            index_no = len(datasets)-1
    except Exception as e:
        st.error("File failed to load. Please select a valid CSV file.")
        print("File failed to load.\n" + str(e))
    # Radio buttons for dataset choice
    chosen_dataset = dataset_container.radio(":bar_chart: ë°ì´í„°ë¥¼ ì„ íƒí•˜ì„¸ìš”:",datasets.keys(),index=index_no)#,horizontal=True,)

    # Check boxes for model choice
    st.write(":brain: í˜„ì¬ëŠ” GPT-3.5ë§Œ ì§€ì›í•©ë‹ˆë‹¤.:")
    # Keep a dictionary of whether models are selected or not
    use_model = {}
    for model_desc,model_name in available_models.items():
        label = f"{model_desc} ({model_name})"
        key = f"key_{model_desc}"
        use_model[model_desc] = st.checkbox(label,value=True,key=key)
 
# Text area for query
question = st.text_area(":eyes: ë¬´ì–¼ ë„ì™€ë“œë¦´ê¹Œìš”?",height=10)
go_btn = st.button("ìƒì„±")

# Make a list of the models which have been selected
selected_models = [model_name for model_name, choose_model in use_model.items() if choose_model]
model_count = len(selected_models)

thread_id = "thread_5OwySoM21wXjTNrAU1NaXCcZ"
assistant_id = "asst_x3aeIz36Q5NptIOIb5NhIwxK" #ê°œì¸ ê³„ì •ì— ìƒì„±ëœ ì–´ì‹œìŠ¤í„´ìŠ¤






# Execute chatbot query
if go_btn and model_count > 0:
    api_keys_entered = True
    # Check API keys are entered.
    if api_keys_entered:
    # Place for plots depending on how many models
        plots = st.columns(model_count)
        # Get the primer for this dataset
        primer1,primer2 = get_primer(datasets[chosen_dataset],'datasets["'+ chosen_dataset + '"]') 
        # Create model, run the request and print the results
        for plot_num, model_type in enumerate(selected_models):
            with plots[plot_num]:
                st.subheader(model_type)
                try:
                    # Format the question
                    question_to_ask = format_question(primer1, primer2, question, model_type)
                    # Run the question
                    answer=""
                    answer = run_request(question_to_ask, available_models[model_type], key=client)
                    # the answer is the completed Python script so add to the beginning of the script to it.
                    answer = primer2 + answer
                    print("Model: " + model_type)
                    print(answer)
                    plot_area = st.empty()
                    plot_area.pyplot(exec(answer))           
                except Exception as e:
                    if type(e) == openai.APIError:
                        st.error("OpenAI API Error. Please try again a short time later. (" + str(e) + ")")
                    elif type(e) == openai.Timeout:
                        st.error("OpenAI API Error. Your request timed out. Please try again a short time later. (" + str(e) + ")")
                    elif type(e) == openai.RateLimitError:
                        st.error("OpenAI API Error. You have exceeded your assigned rate limit. (" + str(e) + ")")
                    elif type(e) == openai.APIConnectionError:
                        st.error("OpenAI API Error. Error connecting to services. Please check your network/proxy/firewall settings. (" + str(e) + ")")
                    elif type(e) == openai.APIResponseValidationError:
                        st.error("OpenAI API Error. Your request was malformed or missing required parameters. (" + str(e) + ")")
                    elif type(e) == openai.AuthenticationError:
                        st.error("Please enter a valid OpenAI API Key. (" + str(e) + ")")
                    elif type(e) == openai.OpenAIError:
                        st.error("OpenAI Service is currently unavailable. Please try again a short time later. (" + str(e) + ")")               
                    else:
                        st.error("Unfortunately the code generated from the model contained errors and was unable to execute.")

# Display the datasets in a list of tabs
# Create the tabs
tab_list = st.tabs(datasets.keys())

# Load up each tab with a dataset
for dataset_num, tab in enumerate(tab_list):
    with tab:
        # Can't get the name of the tab! Can't index key list. So convert to list and index
        dataset_name = list(datasets.keys())[dataset_num]
        st.subheader(dataset_name)
        st.dataframe(datasets[dataset_name],hide_index=True)

# Insert footer to reference dataset origin  
footer="""<style>.footer {position: fixed;left: 0;bottom: 0;width: 100%;text-align: center;}</style><div class="footer">
<p> <a style='display: block; text-align: center;'> Original work by @frog-land. Modified by @paulinayoun. </a></p></div>"""
st.caption("Original work by @frog-land. Modified by @paulinayoun.")

# Hide menu and footer
hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            </style>
            """
st.markdown(hide_streamlit_style, unsafe_allow_html=True)



# Text area for query
# question = st.text_area(":eyes: ë¬´ì–¼ ë„ì™€ë“œë¦´ê¹Œìš”?",height=10)
# go_btn = st.button("ìƒì„±")

prompt = st.chat_input("ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")
if prompt and model_count > 0:
    api_keys_entered = True
    # Check API keys are entered.
    if api_keys_entered:
    # Place for plots depending on how many models
        plots = st.columns(model_count)
        # Get the primer for this dataset
        primer1,primer2 = get_primer(datasets[chosen_dataset],'datasets["'+ chosen_dataset + '"]') 
        # Create model, run the request and print the results
        for plot_num, model_type in enumerate(selected_models):
            with plots[plot_num]:
                st.subheader(model_type)
                try:
                    # Format the question
                    question_to_ask = format_question(primer1, primer2, question, model_type)
                    # Run the question
                    answer=""
                    answer = run_request(question_to_ask, available_models[model_type], key=client)
                    # the answer is the completed Python script so add to the beginning of the script to it.
                    answer = primer2 + answer
                    print("Model: " + model_type)
                    print(answer)
                    plot_area = st.empty()
                    plot_area.pyplot(exec(answer))           
                except Exception as e:
                    if type(e) == openai.APIError:
                        st.error("OpenAI API Error. Please try again a short time later. (" + str(e) + ")")
                    elif type(e) == openai.Timeout:
                        st.error("OpenAI API Error. Your request timed out. Please try again a short time later. (" + str(e) + ")")
                    elif type(e) == openai.RateLimitError:
                        st.error("OpenAI API Error. You have exceeded your assigned rate limit. (" + str(e) + ")")
                    elif type(e) == openai.APIConnectionError:
                        st.error("OpenAI API Error. Error connecting to services. Please check your network/proxy/firewall settings. (" + str(e) + ")")
                    elif type(e) == openai.APIResponseValidationError:
                        st.error("OpenAI API Error. Your request was malformed or missing required parameters. (" + str(e) + ")")
                    elif type(e) == openai.AuthenticationError:
                        st.error("Please enter a valid OpenAI API Key. (" + str(e) + ")")
                    elif type(e) == openai.OpenAIError:
                        st.error("OpenAI Service is currently unavailable. Please try again a short time later. (" + str(e) + ")")               
                    else:
                        st.error("Unfortunately the code generated from the model contained errors and was unable to execute.")
    print(prompt)
    message = client.beta.threads.messages.create(
        thread_id=thread_id,
        role="user",
        content=prompt
    )
    #ì…ë ¥í•œ ë©”ì„¸ì§€ UIì— í‘œì‹œ
    with st.chat_message(message.role):
        st.write(message.content[0].text.value)

    # run ì‹¤í–‰
    run = client.beta.threads.runs.create(
        thread_id=thread_id,
        assistant_id=assistant_id,
        instructions="ë„ˆëŠ” ì¡°ë§Œê°„ ì™¸ë¶€ê°ì‚¬ì¸ì—ê²Œ ê°ì‚¬ë¥¼ ë°›ê²Œ ë ê±°ì•¼. ë‚´ê°€ ì—…ë¡œë“œí•œ íŒŒì¼ì—ì„œë§Œ ì°¾ì€ ë‹µë³€ì„ í•´ì¤˜. ë§Œì•½, ì—…ë¡œë“œí•œ íŒŒì¼ë‚´ì—ì„œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ê±°ê¸°ì—ì„œ ë‹µë³€ ìƒì„±ì„ ë©ˆì¶°ë„ë˜. ëª©ë¡ì´ 5ì¤„ ì´ìƒì´ ë˜ë©´ ëª©ë¡ ì œëª©ì´ ê°€ë¡œë¡œ ëœ í‘œë¡œ ì •ë¦¬í•´ì¤˜."
    )

    with st.spinner("ì‘ë‹µì„ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤."):
        # run ìƒíƒœ ì²´í¬
        while run.status != "completed":
            print("í™•ì¸ ì¤‘ :",run.status)
            time.sleep(0.2)
            run = client.beta.threads.runs.retrieve(
                thread_id=thread_id,
                run_id=run.id
            )

    #whlie ì—ì„œ ë¹ ì ¸ì™€ msg ë¶ˆëŸ¬ì˜¤ê¸°
    messages = client.beta.threads.messages.list(
        thread_id=thread_id
    )

    # ë§ˆì§€ë§‰ ë©”ì„¸ì§€ì— UI ì¶”ê°€í•˜ê¸°
    with st.chat_message(messages.data[0].role):
        st.write(messages.data[0].content[0].text.value)
#         st.image(image_path, caption="Image Caption")

# file_id = file_id
# image_path = download_image(file_id)

# def download_image(file_id)
# # MessageContentImageFile(image_file=ImageFile(file_id='file-9Blij8vAGdLXr3IkTH3yKoTR'), type='image_file')
        
# # ì´ë¯¸ì§€ íŒŒì¼ IDë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ëŠ” ì½”ë“œ ì¶”ê°€ (ì˜ˆì‹œ ì½”ë“œ, ì‹¤ì œ êµ¬í˜„ì€ APIì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
# # file_id = 'file-9Blij8vAGdLXr3IkTH3yKoTR'
# # image_path = download_image(file_id) # download_imageëŠ” ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ëŠ” í•¨ìˆ˜, ì‹¤ì œ êµ¬í˜„ í•„ìš”

# # ì´ë¯¸ì§€ íŒŒì¼ì„ UIì— í‘œì‹œ
# # with st.chat_message(role):
# #     st.image(image_path, caption="Image Caption") # ì´ë¯¸ì§€ ê²½ë¡œì™€ ìº¡ì…˜ ì„¤ì •